# Bottom-Sea-Detection

## Context and Objectives
Terabytes of acoustic multispectral data are routinely collected by oceanographic vessel on campaign to assess fisheries resources in West African waters. The vessel send out pulses of various frequency's acoustic waves in the water, those waves are reflected back to the source when they meet diverse organisms (fish, plancton, etc) or more generaly solid objects. We call echogram (echo more informally) the corresponding signal. Since there is a large variety of elements interfering with the acoustic signal it is hard (we rely on the work of experts) to interpret and indentify the various organisms that are found by this procedure. Nowadays bottom sea recognition is still being done by the work of experts.
The overall goal of this work is to use machine learning and deep learning methods to automate the task of bottom sea recognition.

## Data
Data has been provided by IRD (Institut de Recherche et DÃ©veloppement), it consists of two files 2011 and 2015 corresponding to two campaigns that took places in those years respectively. We can summarise the relevant information as follows:
* 2011
  * Echogram.mat ~ 28.26 GB
  * Filtering.mat ~ 34.5 GB 
* 2015
  * Echogram.mat ~ 30.45 GB
  * Filtering.mat ~ 47.12 GB

The datasets and the procedure to get them is described in the File Data *Matecho_UserManual_18_05_2017.docx* I also add a screen shot of all the variables of each dataset 


## Methodology

## Result
